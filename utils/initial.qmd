---
title: sparklyr2
---

## Setup python and needed packages

```{r}
#| include: false
library(reticulate)
library(dplyr)
library(dbplyr)

use_python("~/.pyenv/versions/3.9.13/bin/python3.9")
use_virtualenv("sparklyr2")
```


```{r}
#| eval: false
library(reticulate)

virtualenv_create("sparklyr2")
install_python()

pkgs <- c("pyspark", "pandas", "PyArrow", "grpcio", "google-api-python-client", "grpcio_status")

virtualenv_install(
  envname = "sparklyr2",
  packages = pkgs
)
```

## Start Spark Connect session

```{r}
#| eval: false
use_python("~/.pyenv/versions/3.9.13/bin/python3.9")
use_virtualenv("sparklyr2")
```


```{r}
pyspark <- import("pyspark")
pyspark_sql <- pyspark$sql
remote <- pyspark_sql$SparkSession$builder$remote("sc://localhost")
spark <- remote$getOrCreate()
```


## Copy and test data frame

```{r}
df_python <- r_to_py(mtcars)
df_spark <- spark$createDataFrame(df_python)
df_cached <- df_spark$cache()
df_view <- df_cached$createTempView("spark_mtcars")
sql_res <- spark$sql("Select * from spark_mtcars")

head(sql_res$toPandas()) 
```


## Test quick `dplyr` translation

```{r}
library(dplyr)
library(dbplyr)

con <- simulate_hive()
simulated_table <- tbl_lazy(mtcars, con, name = "spark_mtcars") 

dplyr_test <- simulated_table %>% 
  group_by(am) %>% 
  summarise(mean_mpg = mean(mpg, na.rm = TRUE))

remote_query(dplyr_test)
```


```{r}
run_sql <- dplyr_test %>% 
  remote_query() %>% 
  spark$sql() 

run_sql$toPandas()
```

## Close connection

```{r}
spark$client$close()
```

